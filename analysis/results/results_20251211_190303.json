{
  "metadata": {
    "embedding_type": "bert",
    "embedding_dim": 768,
    "num_classes": 6,
    "timestamp": "20251211_190303"
  },
  "results": {
    "MLP": {
      "test_accuracy": 81.90916863652366,
      "macro_f1": 0.7918593447661365,
      "weighted_f1": 0.8209735235588743,
      "history": {
        "train_loss": [
          0.7944586075404111,
          0.6167290254550821,
          0.5729995457565084,
          0.5341188004788231,
          0.47948190394569845,
          0.4434976455043344,
          0.4221629320698626,
          0.37626971917993884,
          0.3525533925961046,
          0.33761050508302803,
          0.30858632703037825,
          0.294327285798157,
          0.28299388245624657
        ],
        "train_accuracy": [
          74.23155958556669,
          79.93792122318183,
          81.22691804739254,
          82.36502895572576,
          83.79485263475549,
          84.9329635430887,
          85.3913693256118,
          86.90741352800012,
          87.7265084999066,
          88.05845751483712,
          89.00400925433617,
          89.60180488295563,
          89.85040739197287
        ],
        "val_loss": [
          0.6526391208171844,
          0.6275588810443878,
          0.6126217246055603,
          0.6235792756080627,
          0.6090288758277893,
          0.6087267637252808,
          0.6336246192455292,
          0.6251764833927155,
          0.6528403162956238,
          0.6536725044250489,
          0.6578572452068329,
          0.6671618521213531,
          0.6641815423965454
        ],
        "val_accuracy": [
          79.09877288271977,
          80.31583182458257,
          80.29571514785758,
          78.92778113055724,
          81.2110239388453,
          80.3560651780326,
          80.7986320659827,
          81.56306578153288,
          81.36189901428284,
          81.31160732247032,
          81.43230738282035,
          81.28143230738281,
          81.36189901428284
        ],
        "val_f1_macro": [
          0.7625145005276757,
          0.7765499445006085,
          0.7764937322075337,
          0.7621859406973663,
          0.7867254357551486,
          0.7776786356980437,
          0.7807897221452769,
          0.7909346938694913,
          0.7887592651133176,
          0.788716992293301,
          0.7901337410042931,
          0.7871914039421349,
          0.7880268446979904
        ]
      },
      "classification_report_text": "                precision    recall  f1-score   support\n\n ENTERTAINMENT      0.800     0.808     0.804      3472\n     PARENTING      0.622     0.694     0.656      1758\n      POLITICS      0.929     0.869     0.898      7121\nSTYLE & BEAUTY      0.799     0.815     0.807      1963\n        TRAVEL      0.783     0.825     0.803      1980\n      WELLNESS      0.775     0.792     0.783      3589\n\n      accuracy                          0.819     19883\n     macro avg      0.785     0.800     0.792     19883\n  weighted avg      0.824     0.819     0.821     19883\n",
      "classification_report": {
        "ENTERTAINMENT": {
          "precision": 0.8001140575990875,
          "recall": 0.8081797235023042,
          "f1-score": 0.80412666571142,
          "support": 3472.0
        },
        "PARENTING": {
          "precision": 0.6224489795918368,
          "recall": 0.6939704209328783,
          "f1-score": 0.656266810112964,
          "support": 1758.0
        },
        "POLITICS": {
          "precision": 0.9289683135605947,
          "recall": 0.8686982165426205,
          "f1-score": 0.8978229317851959,
          "support": 7121.0
        },
        "STYLE & BEAUTY": {
          "precision": 0.7987012987012987,
          "recall": 0.8145695364238411,
          "f1-score": 0.8065573770491803,
          "support": 1963.0
        },
        "TRAVEL": {
          "precision": 0.7828379674017258,
          "recall": 0.8247474747474748,
          "f1-score": 0.8032464338416134,
          "support": 1980.0
        },
        "WELLNESS": {
          "precision": 0.7745979831016626,
          "recall": 0.791864028977431,
          "f1-score": 0.7831358500964453,
          "support": 3589.0
        },
        "accuracy": 0.8190916863652367,
        "macro avg": {
          "precision": 0.7846114333260342,
          "recall": 0.8003382335210917,
          "f1-score": 0.7918593447661365,
          "support": 19883.0
        },
        "weighted avg": {
          "precision": 0.824088249314963,
          "recall": 0.8190916863652367,
          "f1-score": 0.8209735235588743,
          "support": 19883.0
        }
      }
    },
    "CNN": {
      "test_accuracy": 43.921943368706934,
      "macro_f1": 0.4087261255530967,
      "weighted_f1": 0.44855049712114864,
      "history": {
        "train_loss": [
          1.5506656327668358,
          1.4601706213810866,
          1.4383271108655369,
          1.4269457599695992,
          1.4069700013188755,
          1.395169396610821,
          1.3897715403753168,
          1.383292373488931,
          1.3750563053523792,
          1.367879413506564
        ],
        "train_accuracy": [
          38.991794680193706,
          45.06315653336016,
          46.252999755708515,
          46.9485119774677,
          47.934299961200765,
          48.55652473810516,
          48.62262713934673,
          49.280777134317205,
          49.59260802713072,
          49.8728247280461
        ],
        "val_loss": [
          2.243730068206787,
          1.9091500878334045,
          1.858313262462616,
          2.354661226272583,
          1.6812232851982116,
          1.4571352124214172,
          1.8532899022102356,
          1.5907515645027162,
          1.5291329979896546,
          1.399835181236267
        ],
        "val_accuracy": [
          36.46147656407162,
          37.2158519412593,
          24.904445785556227,
          21.32367732850533,
          46.08730637698652,
          44.8098974049487,
          24.793804063568697,
          34.03741701870851,
          40.43452021726011,
          44.11587205793603
        ],
        "val_f1_macro": [
          0.1624312232589785,
          0.27204118159195617,
          0.25074402376197263,
          0.13476975229359714,
          0.3178528370332408,
          0.4075300834665064,
          0.26263052045789925,
          0.35986974274253264,
          0.3626742263331601,
          0.41442910489952545
        ]
      },
      "classification_report_text": "                precision    recall  f1-score   support\n\n ENTERTAINMENT      0.404     0.654     0.499      3472\n     PARENTING      0.194     0.505     0.280      1758\n      POLITICS      0.773     0.439     0.560      7121\nSTYLE & BEAUTY      0.432     0.545     0.482      1963\n        TRAVEL      0.335     0.296     0.314      1980\n      WELLNESS      0.560     0.220     0.316      3589\n\n      accuracy                          0.439     19883\n     macro avg      0.450     0.443     0.409     19883\n  weighted avg      0.541     0.439     0.449     19883\n",
      "classification_report": {
        "ENTERTAINMENT": {
          "precision": 0.40377090003557453,
          "recall": 0.6538018433179723,
          "f1-score": 0.49923026171101825,
          "support": 3472.0
        },
        "PARENTING": {
          "precision": 0.19414079580236118,
          "recall": 0.5051194539249146,
          "f1-score": 0.2804801010739103,
          "support": 1758.0
        },
        "POLITICS": {
          "precision": 0.7727272727272727,
          "recall": 0.43926414829377897,
          "f1-score": 0.5601217656012176,
          "support": 7121.0
        },
        "STYLE & BEAUTY": {
          "precision": 0.4317998385794996,
          "recall": 0.5450840550178299,
          "f1-score": 0.48187345192524206,
          "support": 1963.0
        },
        "TRAVEL": {
          "precision": 0.3352402745995423,
          "recall": 0.295959595959596,
          "f1-score": 0.3143776824034335,
          "support": 1980.0
        },
        "WELLNESS": {
          "precision": 0.5598018400566172,
          "recall": 0.22039565338534411,
          "f1-score": 0.3162734906037585,
          "support": 3589.0
        },
        "accuracy": 0.43921943368706934,
        "macro avg": {
          "precision": 0.44958015363347786,
          "recall": 0.44327079164990596,
          "f1-score": 0.4087261255530967,
          "support": 19883.0
        },
        "weighted avg": {
          "precision": 0.5414832079583978,
          "recall": 0.43921943368706934,
          "f1-score": 0.44855049712114864,
          "support": 19883.0
        }
      }
    },
    "Transformer": {
      "test_accuracy": 81.02901976562893,
      "macro_f1": 0.7830728080273884,
      "weighted_f1": 0.8129724452460958,
      "history": {
        "train_loss": [
          0.9655102640390396,
          0.702376136008431,
          0.6670724574257346,
          0.6477264420074575,
          0.6340549518080318,
          0.6286365626489415,
          0.6175458063097561,
          0.6131618838099873,
          0.5929496446076561,
          0.5843578182599124,
          0.5811515345292932,
          0.5769447324907079,
          0.5620731930522358,
          0.5594909156070036,
          0.5528899321661276,
          0.5454838578315342,
          0.5396705957896569,
          0.5363868698477745,
          0.5319293912719277,
          0.5284058495479471
        ],
        "train_accuracy": [
          66.11246030263403,
          77.24209285950366,
          78.26093204385751,
          78.88603083820719,
          79.30276336777364,
          79.46514535343229,
          79.81433847303452,
          79.86607078704968,
          80.45093333716535,
          80.60038224432023,
          80.74552012530717,
          80.84898475333745,
          81.21398496888877,
          81.38642601560592,
          81.52437885297964,
          81.81034358878559,
          81.76148529221572,
          81.99571771400652,
          81.96841454827631,
          82.1523516647746
        ],
        "val_loss": [
          0.7427112936973572,
          0.688306313753128,
          0.6513695180416107,
          0.6649638116359711,
          0.673984032869339,
          0.6600772976875305,
          0.6399202942848206,
          0.6511905908584594,
          0.6404307723045349,
          0.6334094226360321,
          0.6579765975475311,
          0.6427115440368653,
          0.6319166004657746,
          0.6390166759490967,
          0.6363237082958222,
          0.6277224957942963,
          0.6268913388252259,
          0.6271353960037231,
          0.6272929787635804,
          0.6264039039611816
        ],
        "val_accuracy": [
          75.34701267350634,
          78.99818949909475,
          77.83142224904446,
          79.97384832025749,
          80.004023335345,
          79.91349829008247,
          78.89760611546973,
          79.49104807885738,
          80.25548179440756,
          80.52705693019513,
          80.18507342587004,
          80.04425668879502,
          80.68799034399517,
          79.86320659826997,
          80.82880708107021,
          80.56729028364514,
          80.21524844095755,
          80.26554013277007,
          80.10460671897003,
          80.34600683967008
        ],
        "val_f1_macro": [
          0.7223686561861875,
          0.7617150981218205,
          0.7551532865666202,
          0.7737587224199137,
          0.7713612861634115,
          0.7756451914605661,
          0.7637153874485306,
          0.7676262667484237,
          0.7745490885787035,
          0.7789026068678627,
          0.7766870964081362,
          0.7737407307611783,
          0.7818032181156712,
          0.7709939319071074,
          0.7812101496431251,
          0.7799340807508944,
          0.7764944268972783,
          0.7765430829076122,
          0.7750989840685523,
          0.7776921536614004
        ]
      },
      "classification_report_text": "                precision    recall  f1-score   support\n\n ENTERTAINMENT      0.784     0.797     0.790      3472\n     PARENTING      0.595     0.708     0.647      1758\n      POLITICS      0.932     0.858     0.894      7121\nSTYLE & BEAUTY      0.802     0.804     0.803      1963\n        TRAVEL      0.772     0.811     0.791      1980\n      WELLNESS      0.767     0.781     0.774      3589\n\n      accuracy                          0.810     19883\n     macro avg      0.775     0.793     0.783     19883\n  weighted avg      0.818     0.810     0.813     19883\n",
      "classification_report": {
        "ENTERTAINMENT": {
          "precision": 0.7838526912181303,
          "recall": 0.7969470046082949,
          "f1-score": 0.7903456155384176,
          "support": 3472.0
        },
        "PARENTING": {
          "precision": 0.5952153110047846,
          "recall": 0.7076222980659841,
          "f1-score": 0.6465696465696466,
          "support": 1758.0
        },
        "POLITICS": {
          "precision": 0.931859756097561,
          "recall": 0.8584468473528999,
          "f1-score": 0.8936481251370514,
          "support": 7121.0
        },
        "STYLE & BEAUTY": {
          "precision": 0.8022369089984749,
          "recall": 0.803871625063678,
          "f1-score": 0.8030534351145038,
          "support": 1963.0
        },
        "TRAVEL": {
          "precision": 0.7717443536761173,
          "recall": 0.8111111111111111,
          "f1-score": 0.790938192563408,
          "support": 1980.0
        },
        "WELLNESS": {
          "precision": 0.7668946648426812,
          "recall": 0.7809974923376986,
          "f1-score": 0.7738818332413031,
          "support": 3589.0
        },
        "accuracy": 0.8102901976562893,
        "macro avg": {
          "precision": 0.7753006143062916,
          "recall": 0.7931660630899445,
          "f1-score": 0.7830728080273884,
          "support": 19883.0
        },
        "weighted avg": {
          "precision": 0.8177301316999241,
          "recall": 0.8102901976562893,
          "f1-score": 0.8129724452460958,
          "support": 19883.0
        }
      }
    }
  }
}